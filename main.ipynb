{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 276,
   "id": "fd932f50",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import json\n",
    "\n",
    "def robust_clean_json(raw_text):\n",
    "    \"\"\"\n",
    "    Attempt to extract a single JSON object from raw_text.\n",
    "    1) Strip surrounding whitespace.\n",
    "    2) Remove leading/trailing markdown fences (```json etc).\n",
    "    3) Find the first '{' and the matching closing '}' (simple bracket matching).\n",
    "    4) Return the substring or raise ValueError if not found.\n",
    "    \"\"\"\n",
    "    if not isinstance(raw_text, str):\n",
    "        raise ValueError(\"Input to robust_clean_json must be a string.\")\n",
    "    s = raw_text.strip()\n",
    "\n",
    "    # remove common fences and leading labels\n",
    "    # remove fenced code blocks (```json ... ``` or ``` ... ```)\n",
    "    s = re.sub(r\"^```(?:json)?\\s*\", \"\", s, flags=re.IGNORECASE)\n",
    "    s = re.sub(r\"\\s*```$\", \"\", s)\n",
    "\n",
    "    # remove possible leading lines like \"json\" or \"JSON\" or \"output:\"\n",
    "    s = re.sub(r'^(json|JSON|output:|Output:)\\s*', \"\", s)\n",
    "\n",
    "    # find first '{'\n",
    "    start = s.find('{')\n",
    "    if start == -1:\n",
    "        raise ValueError(\"No JSON object start '{' found in LLM output.\")\n",
    "\n",
    "    # simple bracket matching to find corresponding closing brace\n",
    "    depth = 0\n",
    "    end = -1\n",
    "    for i in range(start, len(s)):\n",
    "        if s[i] == '{':\n",
    "            depth += 1\n",
    "        elif s[i] == '}':\n",
    "            depth -= 1\n",
    "            if depth == 0:\n",
    "                end = i\n",
    "                break\n",
    "\n",
    "    if end == -1:\n",
    "        raise ValueError(\"Could not find matching '}' for JSON object in LLM output.\")\n",
    "\n",
    "    candidate = s[start:end+1].strip()\n",
    "\n",
    "    # final sanity: try to parse it\n",
    "    try:\n",
    "        parsed = json.loads(candidate)\n",
    "        return candidate  # return the clean JSON string (or return parsed if you prefer)\n",
    "    except Exception as e:\n",
    "        raise ValueError(f\"Extracted JSON failed to parse: {e}\\nExtracted text:\\n{candidate}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "id": "99d4d229",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import random\n",
    "\n",
    "def load_rules():\n",
    "    with open(\"quant_design_rules.json\", \"r\") as f:\n",
    "        return json.load(f)\n",
    "\n",
    "rules = load_rules()\n",
    "\n",
    "def generator_prompt():\n",
    "    # Convert rules to a readable template for LLM\n",
    "    rules_block = json.dumps(rules, indent=2)\n",
    "\n",
    "    return f\"\"\"\n",
    "You are the Quant Problem Generator Agent.\n",
    "\n",
    "Below are the design rules you MUST follow:\n",
    "{rules_block}\n",
    "\n",
    "Generate ONE brand new quant question following the required JSON schema.\n",
    "\n",
    "RULES:\n",
    "- Use realistic numbers.\n",
    "- Must belong to any of these categories: {rules['output_schema']['category']}\n",
    "- Follow one of the templates.\n",
    "- Ensure hidden_solution matches the correct answer.\n",
    "- Provide 4 MCQs, unique, one correct.\n",
    "- Return ONLY JSON. No markdown.\n",
    "\n",
    "Output MUST be valid JSON and match this structure:\n",
    "\n",
    "{{\n",
    "  \"id\": \"string\",\n",
    "  \"category\": \"string\",\n",
    "  \"difficulty\": \"Easy|Medium|Hard\",\n",
    "  \"question\": \"string\",\n",
    "  \"variables\": {{}},\n",
    "  \"options\": {{\"A\": 0, \"B\": 0, \"C\": 0, \"D\": 0}},\n",
    "  \"correct_option\": \"A\",\n",
    "  \"hidden_solution\": \"string\",\n",
    "  \"units\": \"string\"\n",
    "}}\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "def generator_agent(call_llm):\n",
    "    prompt = generator_prompt()\n",
    "    raw = call_llm(prompt)\n",
    "\n",
    "    if raw is None:\n",
    "        print(\"Generator returned None\")\n",
    "        return None\n",
    "\n",
    "    cleaned = raw.strip()\n",
    "\n",
    "    # Remove common markdown fences quickly\n",
    "    if cleaned.startswith(\"```\"):\n",
    "        # if model returned ```json\\n{...}\\n```, take inner content first\n",
    "        parts = cleaned.split(\"```\")\n",
    "        # find first non-empty segment that contains '{'\n",
    "        inner = next((p for p in parts if '{' in p), cleaned)\n",
    "        cleaned = inner.strip()\n",
    "\n",
    "    # Try normal json.loads first (fast path)\n",
    "    try:\n",
    "        return json.loads(cleaned)\n",
    "    except Exception as e1:\n",
    "        # Defensive: attempt robust extraction\n",
    "        try:\n",
    "            jstr = robust_clean_json(raw)\n",
    "            return json.loads(jstr)\n",
    "        except Exception as e2:\n",
    "            print(\"Generator JSON ERROR:\", e2)\n",
    "            print(\"LLM OUTPUT (raw):\", raw[:1000])  # print first 1000 chars for debug\n",
    "            return None\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "id": "96b3f088",
   "metadata": {},
   "outputs": [],
   "source": [
    "def solver_A_prompt(question_json):\n",
    "    return f\"\"\"\n",
    "You are Solver Agent A.\n",
    "You must solve the following quantitative word problem using correct algebra and step-by-step reasoning.\n",
    "\n",
    "IMPORTANT RULES:\n",
    "- Use ONLY the values given in the problem.\n",
    "- Build equations clearly.\n",
    "- Show ALL steps of reasoning.\n",
    "- Do not skip conversions.\n",
    "- Do not hallucinate extra information.\n",
    "- Do NOT modify any numbers in the story.\n",
    "- Produce ONE numeric final answer.\n",
    "- Output ONLY valid JSON.\n",
    "\n",
    "Return exactly this JSON format:\n",
    "\n",
    "{{\n",
    "  \"equations\": [\"...\"],\n",
    "  \"steps\": [\"...\"],\n",
    "  \"final_answer\": 0,\n",
    "  \"confidence\": \"High|Medium|Low\"\n",
    "}}\n",
    "\n",
    "Problem to solve:\n",
    "{json.dumps(question_json, indent=2)}\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "id": "44395814",
   "metadata": {},
   "outputs": [],
   "source": [
    "def solver_agent_A(question_json, call_llm):\n",
    "    prompt = solver_A_prompt(question_json)\n",
    "    raw = call_llm(prompt)\n",
    "\n",
    "    if raw is None:\n",
    "        print(\"Solver A: No output from LLM.\")\n",
    "        return None\n",
    "\n",
    "    text = raw.strip()\n",
    "\n",
    "    # Remove ```json or ``` wrappers\n",
    "    if text.startswith(\"```\"):\n",
    "        parts = text.split(\"```\")\n",
    "        text = next((p for p in parts if \"{\" in p), text).strip()\n",
    "\n",
    "    # Remove accidental prefixes like: json, JSON, Output:\n",
    "    for prefix in [\"json\", \"JSON\", \"Json\", \"output:\", \"Output:\"]:\n",
    "        if text.startswith(prefix):\n",
    "            text = text[len(prefix):].strip()\n",
    "\n",
    "    # Extract pure JSON block using bracket matching\n",
    "    start = text.find(\"{\")\n",
    "    end = text.rfind(\"}\")\n",
    "    if start == -1 or end == -1:\n",
    "        print(\"Solver A JSON ERROR: No JSON object found.\")\n",
    "        print(\"LLM OUTPUT:\", raw)\n",
    "        return None\n",
    "\n",
    "    json_str = text[start:end+1]\n",
    "\n",
    "    try:\n",
    "        data = json.loads(json_str)\n",
    "        return data\n",
    "    except Exception as e:\n",
    "        print(\"Solver A JSON PARSE ERROR:\", e)\n",
    "        print(\"Extracted JSON:\", json_str)\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "id": "7a423ecd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def solver_B_prompt(question_json):\n",
    "    return f\"\"\"\n",
    "You are Solver Agent B.\n",
    "\n",
    "Your job is to solve the following quantitative word problem WITHOUT using algebra.\n",
    "Instead use:\n",
    "- reverse checking,\n",
    "- brute-force substitution,\n",
    "- option elimination,\n",
    "- logic-based reasoning.\n",
    "\n",
    "RULES:\n",
    "- Check each MCQ option to see which one satisfies the problem.\n",
    "- Do NOT modify story values.\n",
    "- Do NOT add new numbers.\n",
    "- No algebraic manipulation like Solver A.\n",
    "- Only check by plugging values back.\n",
    "\n",
    "Return ONLY valid JSON in this format:\n",
    "\n",
    "{{\n",
    "  \"checked_options\": {{}},\n",
    "  \"final_answer\": 0,\n",
    "  \"reasoning\": [\"...\"],\n",
    "  \"confidence\": \"High|Medium|Low\"\n",
    "}}\n",
    "\n",
    "Problem:\n",
    "{json.dumps(question_json, indent=2)}\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "id": "377a2ad5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def solver_agent_B(question_json, call_llm):\n",
    "    prompt = solver_B_prompt(question_json)\n",
    "    raw = call_llm(prompt)\n",
    "\n",
    "    if raw is None:\n",
    "        print(\"Solver B: No output from LLM.\")\n",
    "        return None\n",
    "\n",
    "    text = raw.strip()\n",
    "\n",
    "    # Remove code fences ```json ... ```\n",
    "    if text.startswith(\"```\"):\n",
    "        parts = text.split(\"```\")\n",
    "        text = next((p for p in parts if \"{\" in p), text).strip()\n",
    "\n",
    "    # Strip leading prefixes like: json, JSON, output:\n",
    "    for prefix in [\"json\", \"JSON\", \"Json\", \"Output:\", \"output:\"]:\n",
    "        if text.startswith(prefix):\n",
    "            text = text[len(prefix):].strip()\n",
    "\n",
    "    # Extract JSON using bracket matching\n",
    "    start = text.find(\"{\")\n",
    "    end = text.rfind(\"}\")\n",
    "    if start == -1 or end == -1:\n",
    "        print(\"Solver B JSON ERROR: No JSON object found.\")\n",
    "        print(\"LLM OUTPUT:\", raw)\n",
    "        return None\n",
    "\n",
    "    json_str = text[start:end+1]\n",
    "\n",
    "    try:\n",
    "        data = json.loads(json_str)\n",
    "        return data\n",
    "    except Exception as e:\n",
    "        print(\"Solver B JSON PARSE ERROR:\", e)\n",
    "        print(\"Extracted JSON:\", json_str)\n",
    "        return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "id": "07cfc120",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate_question(question, solverA, solverB):\n",
    "    issues = []\n",
    "\n",
    "    # 1. Check both solvers returned data\n",
    "    if solverA is None:\n",
    "        issues.append(\"Solver A returned no data.\")\n",
    "    if solverB is None:\n",
    "        issues.append(\"Solver B returned no data.\")\n",
    "\n",
    "    if issues:\n",
    "        return False, issues\n",
    "\n",
    "    # 2. Compare answers numerically\n",
    "    try:\n",
    "        a = float(solverA[\"final_answer\"])\n",
    "        b = float(solverB[\"final_answer\"])\n",
    "        if abs(a - b) > 1e-6:\n",
    "            issues.append(f\"Solver mismatch: A={a}, B={b}\")\n",
    "    except:\n",
    "        issues.append(\"Could not parse answers from solvers.\")\n",
    "\n",
    "    # 3. Check MCQ contains the answer\n",
    "    correct_option = question[\"correct_option\"]\n",
    "    correct_value = question[\"options\"][correct_option]\n",
    "\n",
    "    if abs(float(correct_value) - a) > 1e-6:\n",
    "        issues.append(f\"Correct option value ({correct_value}) does NOT match solver answer ({a}).\")\n",
    "\n",
    "    # 4. Check for impossible values\n",
    "    # Example: negative time, negative speed\n",
    "    if \"variables\" in question:\n",
    "        for k, v in question[\"variables\"].items():\n",
    "            if isinstance(v, (int, float)) and v < 0:\n",
    "                issues.append(f\"Invalid variable: {k} is negative.\")\n",
    "\n",
    "    # 5. Check hidden_solution exists\n",
    "    if \"hidden_solution\" not in question or not question[\"hidden_solution\"]:\n",
    "        issues.append(\"Missing hidden_solution.\")\n",
    "\n",
    "    # 6. Check required fields exist\n",
    "    required_fields = [\"id\", \"category\", \"question\", \"options\", \"correct_option\", \"units\"]\n",
    "    for field in required_fields:\n",
    "        if field not in question:\n",
    "            issues.append(f\"Missing field in question: {field}\")\n",
    "\n",
    "    # Decide validity\n",
    "    is_valid = (len(issues) == 0)\n",
    "    return is_valid, issues\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "id": "9c862e87",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validator_agent(question, solverA_output, solverB_output):\n",
    "    is_valid, issues = validate_question(question, solverA_output, solverB_output)\n",
    "\n",
    "    if is_valid:\n",
    "        return {\n",
    "            \"status\": \"VALID\",\n",
    "            \"issues\": [],\n",
    "            \"final_answer\": solverA_output[\"final_answer\"]\n",
    "        }\n",
    "    else:\n",
    "        return {\n",
    "            \"status\": \"INVALID\",\n",
    "            \"issues\": issues,\n",
    "            \"regenerate\": True\n",
    "        }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "id": "9415f3c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"models\": [\n",
      "    {\n",
      "      \"name\": \"models/gemini-2.5-flash\",\n",
      "      \"version\": \"001\",\n",
      "      \"displayName\": \"Gemini 2.5 Flash\",\n",
      "      \"description\": \"Stable version of Gemini 2.5 Flash, our mid-size multimodal model that supports up to 1 million tokens, released in June of 2025.\",\n",
      "      \"inputTokenLimit\": 1048576,\n",
      "      \"outputTokenLimit\": 65536,\n",
      "      \"supportedGenerationMethods\": [\n",
      "        \"generateContent\",\n",
      "        \"countTokens\",\n",
      "        \"createCachedContent\",\n",
      "        \"batchGenerateContent\"\n",
      "      ],\n",
      "      \"temperature\": 1,\n",
      "      \"topP\": 0.95,\n",
      "      \"topK\": 64,\n",
      "      \"maxTemperature\": 2,\n",
      "      \"thinking\": true\n",
      "    },\n",
      "    {\n",
      "      \"name\": \"models/gemini-2.5-pro\",\n",
      "      \"version\": \"2.5\",\n",
      "      \"displayName\": \"Gemini 2.5 Pro\",\n",
      "      \"description\": \"Stable release (June 17th, 2025) of Gemini 2.5 Pro\",\n",
      "      \"inputTokenLimit\": 1048576,\n",
      "      \"outputTokenLimit\": 65536,\n",
      "      \"supportedGenerationMethods\": [\n",
      "        \"generateContent\",\n",
      "        \"countTokens\",\n",
      "        \"createCachedContent\",\n",
      "        \"batchGenerateContent\"\n",
      "      ],\n",
      "      \"temperature\": 1,\n",
      "      \"topP\": 0.95,\n",
      "      \"topK\": 64,\n",
      "      \"maxTemperature\": 2,\n",
      "      \"thinking\": true\n",
      "    },\n",
      "    {\n",
      "      \"name\": \"models/gemini-2.0-flash\",\n",
      "      \"version\": \"2.0\",\n",
      "      \"displayName\": \"Gemini 2.0 Flash\",\n",
      "      \"description\": \"Gemini 2.0 Flash\",\n",
      "      \"inputTokenLimit\": 1048576,\n",
      "      \"outputTokenLimit\": 8192,\n",
      "      \"supportedGenerationMethods\": [\n",
      "        \"generateContent\",\n",
      "        \"countTokens\",\n",
      "        \"createCachedContent\",\n",
      "        \"batchGenerateContent\"\n",
      "      ],\n",
      "      \"temperature\": 1,\n",
      "      \"topP\": 0.95,\n",
      "      \"topK\": 40,\n",
      "      \"maxTemperature\": 2\n",
      "    },\n",
      "    {\n",
      "      \"name\": \"models/gemini-2.0-flash-001\",\n",
      "      \"version\": \"2.0\",\n",
      "      \"displayName\": \"Gemini 2.0 Flash 001\",\n",
      "      \"description\": \"Stable version of Gemini 2.0 Flash, our fast and versatile multimodal model for scaling across diverse tasks, released in January of 2025.\",\n",
      "      \"inputTokenLimit\": 1048576,\n",
      "      \"outputTokenLimit\": 8192,\n",
      "      \"supportedGenerationMethods\": [\n",
      "        \"generateContent\",\n",
      "        \"countTokens\",\n",
      "        \"createCachedContent\",\n",
      "        \"batchGenerateContent\"\n",
      "      ],\n",
      "      \"temperature\": 1,\n",
      "      \"topP\": 0.95,\n",
      "      \"topK\": 40,\n",
      "      \"maxTemperature\": 2\n",
      "    },\n",
      "    {\n",
      "      \"name\": \"models/gemini-2.0-flash-lite-001\",\n",
      "      \"version\": \"2.0\",\n",
      "      \"displayName\": \"Gemini 2.0 Flash-Lite 001\",\n",
      "      \"description\": \"Stable version of Gemini 2.0 Flash-Lite\",\n",
      "      \"inputTokenLimit\": 1048576,\n",
      "      \"outputTokenLimit\": 8192,\n",
      "      \"supportedGenerationMethods\": [\n",
      "        \"generateContent\",\n",
      "        \"countTokens\",\n",
      "        \"createCachedContent\",\n",
      "        \"batchGenerateContent\"\n",
      "      ],\n",
      "      \"temperature\": 1,\n",
      "      \"topP\": 0.95,\n",
      "      \"topK\": 40,\n",
      "      \"maxTemperature\": 2\n",
      "    },\n",
      "    {\n",
      "      \"name\": \"models/gemini-2.0-flash-lite\",\n",
      "      \"version\": \"2.0\",\n",
      "      \"displayName\": \"Gemini 2.0 Flash-Lite\",\n",
      "      \"description\": \"Gemini 2.0 Flash-Lite\",\n",
      "      \"inputTokenLimit\": 1048576,\n",
      "      \"outputTokenLimit\": 8192,\n",
      "      \"supportedGenerationMethods\": [\n",
      "        \"generateContent\",\n",
      "        \"countTokens\",\n",
      "        \"createCachedContent\",\n",
      "        \"batchGenerateContent\"\n",
      "      ],\n",
      "      \"temperature\": 1,\n",
      "      \"topP\": 0.95,\n",
      "      \"topK\": 40,\n",
      "      \"maxTemperature\": 2\n",
      "    },\n",
      "    {\n",
      "      \"name\": \"models/gemini-2.5-flash-lite\",\n",
      "      \"version\": \"001\",\n",
      "      \"displayName\": \"Gemini 2.5 Flash-Lite\",\n",
      "      \"description\": \"Stable version of Gemini 2.5 Flash-Lite, released in July of 2025\",\n",
      "      \"inputTokenLimit\": 1048576,\n",
      "      \"outputTokenLimit\": 65536,\n",
      "      \"supportedGenerationMethods\": [\n",
      "        \"generateContent\",\n",
      "        \"countTokens\",\n",
      "        \"createCachedContent\",\n",
      "        \"batchGenerateContent\"\n",
      "      ],\n",
      "      \"temperature\": 1,\n",
      "      \"topP\": 0.95,\n",
      "      \"topK\": 64,\n",
      "      \"maxTemperature\": 2,\n",
      "      \"thinking\": true\n",
      "    },\n",
      "    {\n",
      "      \"name\": \"models/embedding-001\",\n",
      "      \"version\": \"001\",\n",
      "      \"displayName\": \"Embedding 001\",\n",
      "      \"description\": \"Obtain a distributed representation of a text.\",\n",
      "      \"inputTokenLimit\": 2048,\n",
      "      \"outputTokenLimit\": 1,\n",
      "      \"supportedGenerationMethods\": [\n",
      "        \"embedContent\"\n",
      "      ]\n",
      "    },\n",
      "    {\n",
      "      \"name\": \"models/text-embedding-004\",\n",
      "      \"version\": \"004\",\n",
      "      \"displayName\": \"Text Embedding 004\",\n",
      "      \"description\": \"Obtain a distributed representation of a text.\",\n",
      "      \"inputTokenLimit\": 2048,\n",
      "      \"outputTokenLimit\": 1,\n",
      "      \"supportedGenerationMethods\": [\n",
      "        \"embedContent\"\n",
      "      ]\n",
      "    }\n",
      "  ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "import requests, json\n",
    "\n",
    "API_KEY = \"AIzaSyDuOq31ZoWnaeTrn3e8XasCeiYCCTPZCtM\"\n",
    "\n",
    "response = requests.get(\n",
    "    f\"https://generativelanguage.googleapis.com/v1/models?key={API_KEY}\"\n",
    ")\n",
    "\n",
    "print(json.dumps(response.json(), indent=2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "id": "50715b02",
   "metadata": {},
   "outputs": [],
   "source": [
    "def orchestrator(call_llm, max_questions=5, max_attempts=50):\n",
    "    validated = []\n",
    "    stats = {\n",
    "        \"total_generated\": 0,\n",
    "        \"valid_count\": 0,\n",
    "        \"invalid_count\": 0,\n",
    "        \"attempts\": 0\n",
    "    }\n",
    "\n",
    "    for _ in range(max_attempts):\n",
    "        stats[\"attempts\"] += 1\n",
    "        print(f\"\\n=== Attempt {stats['attempts']} ===\")\n",
    "\n",
    "        # Generate question\n",
    "        q = generator_agent(call_llm)\n",
    "        if q is None:\n",
    "            print(\"âŒ Generator returned invalid JSON.\")\n",
    "            stats[\"invalid_count\"] += 1\n",
    "            continue\n",
    "\n",
    "        stats[\"total_generated\"] += 1\n",
    "\n",
    "        # Solver A\n",
    "        a = solver_agent_A(q, call_llm)\n",
    "        if a is None:\n",
    "            print(\"âŒ Solver A failed.\")\n",
    "            stats[\"invalid_count\"] += 1\n",
    "            continue\n",
    "\n",
    "        # Solver B\n",
    "        b = solver_agent_B(q, call_llm)\n",
    "        if b is None:\n",
    "            print(\"âŒ Solver B failed.\")\n",
    "            stats[\"invalid_count\"] += 1\n",
    "            continue\n",
    "\n",
    "        # VALIDATION (FIXED)\n",
    "        valid, reason = validate_question(q, a, b)\n",
    "        if not valid:\n",
    "            print(f\"âŒ Validator failed: {reason}\")\n",
    "            stats[\"invalid_count\"] += 1\n",
    "            continue\n",
    "\n",
    "        # SUCCESS\n",
    "        print(\"âœ… VALID QUESTION ADDED!\")\n",
    "        validated.append({\"question\": q, \"solverA\": a, \"solverB\": b})\n",
    "        stats[\"valid_count\"] += 1\n",
    "\n",
    "        if stats[\"valid_count\"] >= max_questions:\n",
    "            print(\"\\nðŸŽ‰ ALL VALID QUESTIONS GENERATED!\")\n",
    "            break\n",
    "\n",
    "    return validated, stats\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "id": "1abf05bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "\n",
    "API_KEY = \"AIzaSyDuOq31ZoWnaeTrn3e8XasCeiYCCTPZCtM\"  # your correct cloud key\n",
    "\n",
    "def real_llm(prompt):\n",
    "    url = f\"https://generativelanguage.googleapis.com/v1/models/gemini-2.5-flash:generateContent?key={API_KEY}\"\n",
    "\n",
    "    payload = {\n",
    "        \"contents\": [\n",
    "            {\n",
    "                \"parts\": [\n",
    "                    {\"text\": prompt}\n",
    "                ]\n",
    "            }\n",
    "        ]\n",
    "    }\n",
    "\n",
    "    headers = {\n",
    "        \"Content-Type\": \"application/json\"\n",
    "    }\n",
    "\n",
    "    response = requests.post(url, headers=headers, json=payload)\n",
    "    data = response.json()\n",
    "\n",
    "    try:\n",
    "        return data[\"candidates\"][0][\"content\"][\"parts\"][0][\"text\"]\n",
    "    except Exception:\n",
    "        print(\"âŒ FULL GEMINI RESPONSE:\")\n",
    "        print(json.dumps(data, indent=2))\n",
    "        raise KeyError(\"Gemini did not return expected format.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef300dc0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "id": "cb6a91c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âŒ FULL GEMINI RESPONSE:\n",
      "{\n",
      "  \"error\": {\n",
      "    \"code\": 429,\n",
      "    \"message\": \"You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \\n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 250, model: gemini-2.5-flash\\nPlease retry in 12.745615482s.\",\n",
      "    \"status\": \"RESOURCE_EXHAUSTED\",\n",
      "    \"details\": [\n",
      "      {\n",
      "        \"@type\": \"type.googleapis.com/google.rpc.Help\",\n",
      "        \"links\": [\n",
      "          {\n",
      "            \"description\": \"Learn more about Gemini API quotas\",\n",
      "            \"url\": \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "          }\n",
      "        ]\n",
      "      },\n",
      "      {\n",
      "        \"@type\": \"type.googleapis.com/google.rpc.QuotaFailure\",\n",
      "        \"violations\": [\n",
      "          {\n",
      "            \"quotaMetric\": \"generativelanguage.googleapis.com/generate_content_free_tier_requests\",\n",
      "            \"quotaId\": \"GenerateRequestsPerDayPerProjectPerModel-FreeTier\",\n",
      "            \"quotaDimensions\": {\n",
      "              \"location\": \"global\",\n",
      "              \"model\": \"gemini-2.5-flash\"\n",
      "            },\n",
      "            \"quotaValue\": \"250\"\n",
      "          }\n",
      "        ]\n",
      "      },\n",
      "      {\n",
      "        \"@type\": \"type.googleapis.com/google.rpc.RetryInfo\",\n",
      "        \"retryDelay\": \"12s\"\n",
      "      }\n",
      "    ]\n",
      "  }\n",
      "}\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'Gemini did not return expected format.'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[286]\u001b[39m\u001b[32m, line 27\u001b[39m, in \u001b[36mreal_llm\u001b[39m\u001b[34m(prompt)\u001b[39m\n\u001b[32m     26\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m27\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mdata\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcandidates\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m[\u001b[32m0\u001b[39m][\u001b[33m\"\u001b[39m\u001b[33mcontent\u001b[39m\u001b[33m\"\u001b[39m][\u001b[33m\"\u001b[39m\u001b[33mparts\u001b[39m\u001b[33m\"\u001b[39m][\u001b[32m0\u001b[39m][\u001b[33m\"\u001b[39m\u001b[33mtext\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m     28\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n",
      "\u001b[31mKeyError\u001b[39m: 'candidates'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[287]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mreal_llm\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mHi! Say hello in JSON only.\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[286]\u001b[39m\u001b[32m, line 31\u001b[39m, in \u001b[36mreal_llm\u001b[39m\u001b[34m(prompt)\u001b[39m\n\u001b[32m     29\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mâŒ FULL GEMINI RESPONSE:\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     30\u001b[39m \u001b[38;5;28mprint\u001b[39m(json.dumps(data, indent=\u001b[32m2\u001b[39m))\n\u001b[32m---> \u001b[39m\u001b[32m31\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mGemini did not return expected format.\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mKeyError\u001b[39m: 'Gemini did not return expected format.'"
     ]
    }
   ],
   "source": [
    "real_llm(\"Hi! Say hello in JSON only.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03e85f88",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6e9d6ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Attempt 1 ===\n",
      "âœ… VALID QUESTION ADDED!\n",
      "\n",
      "=== Attempt 2 ===\n",
      "âœ… VALID QUESTION ADDED!\n",
      "\n",
      "=== Attempt 3 ===\n",
      "âœ… VALID QUESTION ADDED!\n",
      "\n",
      "=== Attempt 4 ===\n",
      "âœ… VALID QUESTION ADDED!\n",
      "\n",
      "=== Attempt 5 ===\n",
      "âœ… VALID QUESTION ADDED!\n",
      "\n",
      "ðŸŽ‰ ALL VALID QUESTIONS GENERATED!\n"
     ]
    }
   ],
   "source": [
    "validated, stats = orchestrator(real_llm, max_questions=5)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "922a1b8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_interactive_quiz(validated_questions):\n",
    "    html = \"\"\"\n",
    "<html>\n",
    "<head>\n",
    "<title>Quant Quiz</title>\n",
    "<style>\n",
    "body { font-family: Arial; margin: 40px; }\n",
    ".question { margin-bottom: 30px; padding: 15px; border: 1px solid #ddd; border-radius: 8px; }\n",
    ".options { margin-left: 20px; }\n",
    ".correctAns { color: green; font-weight: bold; }\n",
    ".wrongAns { color: red; font-weight: bold; }\n",
    ".hidden { display: none; }\n",
    "button { padding: 10px 20px; margin-top: 20px; font-size: 16px; }\n",
    "</style>\n",
    "</head>\n",
    "<body>\n",
    "\n",
    "<h1>Quantitative MCQ Quiz</h1>\n",
    "<form id=\"quizForm\">\n",
    "\"\"\"\n",
    "    for idx, item in enumerate(validated_questions, start=1):\n",
    "        q = item[\"question\"]\n",
    "        correct = q[\"correct_option\"]\n",
    "        correct_value = q[\"options\"][correct]\n",
    "\n",
    "        html += f\"\"\"\n",
    "<div class='question'>\n",
    "<h3>Q{idx}. {q['question']}</h3>\n",
    "<div class='options'>\n",
    "<label><input type='radio' name='q{idx}' value='A'> A. {q['options']['A']}</label><br>\n",
    "<label><input type='radio' name='q{idx}' value='B'> B. {q['options']['B']}</label><br>\n",
    "<label><input type='radio' name='q{idx}' value='C'> C. {q['options']['C']}</label><br>\n",
    "<label><input type='radio' name='q{idx}' value='D'> D. {q['options']['D']}</label><br>\n",
    "</div>\n",
    "\n",
    "<p id='ans{idx}' class='hidden'>\n",
    "Correct Answer: <b>{correct} ({correct_value})</b>\n",
    "</p>\n",
    "\n",
    "</div>\n",
    "\"\"\"\n",
    "    # JS Logic\n",
    "    html += \"\"\"\n",
    "<button type=\"button\" onclick=\"submitQuiz()\">Submit Quiz</button>\n",
    "</form>\n",
    "\n",
    "<h2 id=\"score\"></h2>\n",
    "\n",
    "<script>\n",
    "function submitQuiz() {\n",
    "    let score = 0;\n",
    "\"\"\"\n",
    "\n",
    "    for idx, item in enumerate(validated_questions, start=1):\n",
    "        correct = item[\"question\"][\"correct_option\"]\n",
    "\n",
    "        html += f\"\"\"\n",
    "    var selected{idx} = document.querySelector(\"input[name='q{idx}']:checked\");\n",
    "    var ansBox{idx} = document.getElementById('ans{idx}');\n",
    "\n",
    "    if (selected{idx}) {{\n",
    "        if (selected{idx}.value == \"{correct}\") {{\n",
    "            score++;\n",
    "            ansBox{idx}.className = 'correctAns';\n",
    "        }} else {{\n",
    "            ansBox{idx}.className = 'wrongAns';\n",
    "        }}\n",
    "    }} else {{\n",
    "        ansBox{idx}.className = 'wrongAns';\n",
    "    }}\n",
    "\n",
    "    ansBox{idx}.style.display = 'block';\n",
    "\"\"\"\n",
    "\n",
    "    total = len(validated_questions)\n",
    "    html += f\"\"\"\n",
    "    document.getElementById(\"score\").innerHTML =\n",
    "        \"Your Score: \" + score + \" / {total}\";\n",
    "    \n",
    "</script>\n",
    "\n",
    "</body>\n",
    "</html>\n",
    "\"\"\"\n",
    "    return html\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bd0016e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_interactive_quiz(validated_questions, filename=\"quiz.html\"):\n",
    "    html = generate_interactive_quiz(validated_questions)\n",
    "    with open(filename, \"w\", encoding=\"utf-8\") as f:\n",
    "        f.write(html)\n",
    "    print(\"Interactive quiz saved as\", filename)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b182e80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Interactive quiz saved as quiz.html\n"
     ]
    }
   ],
   "source": [
    "save_interactive_quiz(validated)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c32c18c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_accuracy_report(stats):\n",
    "    total = stats[\"total_generated\"]\n",
    "    valid = stats[\"valid_count\"]\n",
    "    invalid = stats[\"invalid_count\"]\n",
    "\n",
    "    acceptance_rate = (valid / total * 100) if total > 0 else 0\n",
    "\n",
    "    report = {\n",
    "        \"total_generated\": total,\n",
    "        \"valid_questions\": valid,\n",
    "        \"invalid_questions\": invalid,\n",
    "        \"acceptance_rate_percent\": round(acceptance_rate, 2),\n",
    "        \"total_attempts\": stats[\"attempts\"]\n",
    "    }\n",
    "\n",
    "    return report\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c52a2489",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_accuracy_report(report, filename=\"accuracy_report.json\"):\n",
    "    import json\n",
    "    with open(filename, \"w\") as f:\n",
    "        json.dump(report, f, indent=4)\n",
    "    print(f\"Accuracy report saved as {filename}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77ad939b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'total_generated': 5,\n",
       " 'valid_questions': 5,\n",
       " 'invalid_questions': 0,\n",
       " 'acceptance_rate_percent': 100.0,\n",
       " 'total_attempts': 5}"
      ]
     },
     "execution_count": 274,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "report = generate_accuracy_report(stats)\n",
    "report\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a66b566",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy report saved as accuracy_report.json\n"
     ]
    }
   ],
   "source": [
    "save_accuracy_report(report)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e19256c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
